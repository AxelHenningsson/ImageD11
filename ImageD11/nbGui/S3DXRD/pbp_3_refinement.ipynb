{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 12/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook will try to perform a point-by-point strain refinement of your pbp index results.  \n",
    "As with the pbp index, the results of this process are multi-valued.  \n",
    "You can run 4_visualise to convert the refinement results to an accurate single-valued map.  \n",
    "\n",
    "### NOTE: It is highly recommended to run this notebook on a Jupyter server with many cores and a lot of RAM.  \n",
    "The compute_origins() function in particular runs locally and can be compute-intensive for large datasets.  \n",
    "If this is a big scan (e.g 100 million + 2D peaks), you should definitely refine on the cluster rather than locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged with 'parameters'\n",
    "# to view the tag, select the cell, then find the settings gear icon (right or left sidebar) and look for Cell Tags\n",
    "\n",
    "# python environment stuff\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )\n",
    "\n",
    "# dataset file to import\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "# which phase to refine\n",
    "phase_str = 'Si'\n",
    "\n",
    "# the minimum number of peaks you want a pixel to have to be counted\n",
    "min_unique = 20\n",
    "\n",
    "# threshold for whole-sample mask binarisation\n",
    "manual_threshold = None\n",
    "\n",
    "# refinement parameters\n",
    "y0 = 0.0\n",
    "hkl_tol_origins = 0.05\n",
    "hkl_tol_refine = 0.1\n",
    "hkl_tol_refine_merged = 0.05\n",
    "ds_tol = 0.006\n",
    "ifrac = 6e-3\n",
    "rings_to_refine = None  # can be a list of rings\n",
    "set_mask_from_input = False  # do we mask just from the min_unique value?\n",
    "use_cluster = False\n",
    "\n",
    "dset_prefix = \"top_\"  # some common string in the names of the datasets if processing multiple scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import unitcell\n",
    "import ImageD11.sinograms.dataset\n",
    "from ImageD11.sinograms.point_by_point import PBPMap, nb_inv, PBPRefine\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.nbGui import nb_utils as utils\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's select a phase to index from our parameters json\n",
    "\n",
    "ref_ucell = ds.phases.unitcells[phase_str]\n",
    "\n",
    "print(ref_ucell.lattice_parameters, ref_ucell.spacegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's load our point-by-point map from disk\n",
    "\n",
    "pmap = PBPMap(ds.pbpfile.replace('.txt', f'_{phase_str}.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot a histogram of unique peaks per ubi\n",
    "\n",
    "pmap.plot_nuniq_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose the minimum number of peaks you want a pixel to have to be counted\n",
    "\n",
    "pmap.choose_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's plot the result of your choice\n",
    "\n",
    "pmap.plot_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the 2D peaks from disk\n",
    "\n",
    "cf_2d = ds.get_cf_2d()\n",
    "ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "print(cf_2d.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a refinement manager object\n",
    "\n",
    "refine = PBPRefine(dset=ds, y0=y0, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str, forref=rings_to_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the default paths of the refinement manager to append the phase name\n",
    "# so we don't conflict\n",
    "\n",
    "refine.own_filename = os.path.splitext(refine.own_filename)[0] + f'_{phase_str}.h5'\n",
    "refine.icolf_filename = os.path.splitext(refine.icolf_filename)[0] + f'_{phase_str}.h5'\n",
    "refine.pbpmap_filename = os.path.splitext(refine.pbpmap_filename)[0] + f'_{phase_str}.h5'\n",
    "refine.refinedmap_filename = os.path.splitext(refine.refinedmap_filename)[0] + f'_{phase_str}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tell it which point-by-point map we are refining\n",
    "\n",
    "refine.setmap(pmap)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose 2D peaks to refine with\n",
    "\n",
    "refine.setpeaks(cf_2d)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadpeaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the peaks you selected\n",
    "\n",
    "refine.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate a single-valued map to refine on\n",
    "\n",
    "refine.setsingle(refine.pbpmap, minpeaks=min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set whole-sample mask to choose where to refine\n",
    "# if use_singlemap is true, we will generate a mask simply based on where self.singlemap > min_unique\n",
    "\n",
    "refine.setmask(manual_threshold=manual_threshold, doplot=True, use_singlemap=set_mask_from_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute diffraction origins - these will be added as a column to refine.icolf\n",
    "# will then save the new column to disk to avoid re-computation\n",
    "\n",
    "refine.get_origins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the refinement\n",
    "# if compute_origins took more than a couple of minutes to run, I suggest setting use_cluster=True below\n",
    "# otherwise if you asked for lots of cores and RAM on this Jupyter instance, you can run it locally (use_cluster=False)\n",
    "\n",
    "refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure refinement is saved to disk\n",
    "\n",
    "refine.to_h5()\n",
    "\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "# you can optionally skip samples\n",
    "# skips_dict = {\n",
    "#     \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "# }\n",
    "# otherwise by default skip nothing:\n",
    "skips_dict = {\n",
    "    ds.sample: []\n",
    "}\n",
    "\n",
    "sample_list = [ds.sample, ]\n",
    "\n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        if os.path.exists(os.path.splitext(ds.refoutfile)[0] + f'_{phase_str}.h5'):\n",
    "            print(f\"Already have PBP refinement output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        pbpfile = ds.pbpfile.replace('.txt', f'_{phase_str}.txt')\n",
    "        if not os.path.exists(pbpfile):\n",
    "            print(f\"Can't find PBP indexing file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        cf_2d = ds.get_cf_2d()\n",
    "        ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "        if not os.path.exists(ds.col2dfile):\n",
    "            ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)\n",
    "        \n",
    "        pmap = PBPMap(pbpfile)\n",
    "        pmap.choose_best(min_unique)\n",
    "        \n",
    "        refine = PBPRefine(dset=ds, y0=y0, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str, forref=rings_to_refine)\n",
    "        \n",
    "        # change the default paths of the refinement manager to append the phase name\n",
    "        # so we don't conflict\n",
    "\n",
    "        refine.own_filename = os.path.splitext(refine.own_filename)[0] + f'_{phase_str}.h5'\n",
    "        refine.icolf_filename = os.path.splitext(refine.icolf_filename)[0] + f'_{phase_str}.h5'\n",
    "        refine.pbpmap_filename = os.path.splitext(refine.pbpmap_filename)[0] + f'_{phase_str}.h5'\n",
    "        refine.refinedmap_filename = os.path.splitext(refine.refinedmap_filename)[0] + f'_{phase_str}.h5'\n",
    "        \n",
    "        refine.setmap(pmap)\n",
    "        refine.setpeaks(cf_2d)\n",
    "        refine.setsingle(refine.pbpmap, minpeaks=min_unique)\n",
    "        refine.setmask(manual_threshold=manual_threshold, doplot=False, use_singlemap=set_mask_from_input)\n",
    "        refine.get_origins()\n",
    "        refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)\n",
    "        if not use_cluster:\n",
    "            # wait to complete locally, then save\n",
    "            refine.to_h5()\n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
