{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 16/01/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a bug with the current version of ImageD11 in the site-wide Jupyter env.\n",
    "# This has been fixed here: https://github.com/FABLE-3DXRD/ImageD11/commit/4af88b886b1775585e868f2339a0eb975401468f\n",
    "# Until a new release has been made and added to the env, we need to get the latest version of ImageD11 from GitHub\n",
    "# Put it in your home directory somewhere\n",
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "id11_code_path = \"/home/esrf/james1997a/Code/ImageD11\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os, glob, pprint\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import h5py\n",
    "\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ImageD11.grain\n",
    "import ImageD11.unitcell\n",
    "import ImageD11.indexing\n",
    "import ImageD11.columnfile\n",
    "import ImageD11.refinegrains\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.sinograms.lima_segmenter\n",
    "import ImageD11.sinograms.assemble_label\n",
    "\n",
    "from ImageD11.blobcorrector import eiger_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: specify your experimental directory\n",
    "\n",
    "base_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211\"\n",
    "\n",
    "rawdata_path = os.path.join(base_dir, 'RAW_DATA')\n",
    "\n",
    "!ls -lrt {rawdata_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR_nscope\"\n",
    "dataset = \"top_700um\"\n",
    "\n",
    "# USER: specify path to detector mask\n",
    "\n",
    "processed_data_root_dir = os.path.join(base_dir, 'PROCESSED_DATA/James')  # USER: modify this to change the destination folder if desired\n",
    "sparse_pixels_dir = os.path.join(processed_data_root_dir, \"SparsePixels_NewMask\")  # USER: modify this to change the name of the SparsePixels folder inside processed_data_root_dir\n",
    "\n",
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(sparse_pixels_dir, f\"ds_{sample}_{dataset}.h5\" )\n",
    "sparse_path = os.path.join(sparse_pixels_dir, f'{sample}_{dataset}_sparse.h5')\n",
    "pks_path = os.path.join(sparse_pixels_dir, f'pks_{sample}_{dataset}.h5')\n",
    "cf_path = os.path.join(sparse_pixels_dir, f'cf_{sample}_{dataset}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset from file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge your peaks in 2D and 4D\n",
    "\n",
    "peaks_table = ImageD11.sinograms.properties.pks_table.load(pks_path)\n",
    "peaks_4d = peaks_table.pk2dmerge(ds.omega, ds.dty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a mask that selects only 4D peaks greater than 25 pixels in size\n",
    "\n",
    "m = peaks_4d['Number_of_pixels'] > 25\n",
    "\n",
    "# then plot omega vs dty for all peaks - should look sinusoidal\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "counts, xedges, yedges, im = ax.hist2d(peaks_4d['omega'][m], peaks_4d['dty'][m], weights=np.sqrt(peaks_4d['sum_intensity'][m]), bins=(ds.obinedges, ds.ybinedges), norm=matplotlib.colors.LogNorm())\n",
    "ax.set_xlabel(\"Omega angle\")\n",
    "ax.set_ylabel(\"dty\")\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will now generate a cf (columnfile) object each for the 2D and 4D peaks.\n",
    "# These columnfile objects will be corrected for detector spatial distortion\n",
    "# USER: specify the paths to the dxfile and dyfile\n",
    "\n",
    "e2dx_path = os.path.join(processed_data_root_dir, '../CeO2/e2dx_E-08-0173_20231127.edf')\n",
    "e2dy_path = os.path.join(processed_data_root_dir, '../CeO2/e2dy_E-08-0173_20231127.edf')\n",
    "\n",
    "# USER: specify the path to the parameter file\n",
    "\n",
    "par_path = 'Fe_refined.par'\n",
    "\n",
    "spatial_correction_function = eiger_spatial(dxfile=e2dx_path, dyfile=e2dy_path)\n",
    "\n",
    "spatial_correction_dict_4d = spatial_correction_function(peaks_4d)\n",
    "\n",
    "cf_4d = ImageD11.columnfile.colfile_from_dict(spatial_correction_dict_4d)\n",
    "\n",
    "# Filter the columnfile to select only peaks greater than 5 pixels in size\n",
    "\n",
    "print(f\"{cf_4d.nrows} peaks before filtration\")\n",
    "cf_4d.filter(cf_4d.Number_of_pixels > 5)\n",
    "print(f\"{cf_4d.nrows} peaks after filtration\")\n",
    "\n",
    "# calculates the scattering vector (g-vector) geometries using parameters from the file\n",
    "\n",
    "cf_4d.parameters.loadparameters(par_path)\n",
    "\n",
    "cf_4d.updateGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the 4D peaks (fewer of them) as a cake (two-theta vs eta)\n",
    "# if the parameters in the par file are good, these should look like straight lines\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(cf_4d.tth, cf_4d.eta, s=1)\n",
    "\n",
    "ax.set_xlabel(\"Two-theta\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: export CF to an flt so we can play with it with ImageD11_gui\n",
    "# uncomment the below line\n",
    "\n",
    "# cf_4d.writefile(f'{sample}_{dataset}_4d_peaks.flt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strongest_peaks(colf, uself=True, frac=0.995, B=0.2, doplot=None):\n",
    "    # correct intensities for structure factor (decreases with 2theta)\n",
    "    cor_intensity = colf.sum_intensity * (np.exp(colf.ds*colf.ds*B))\n",
    "    if uself:\n",
    "        lf = ImageD11.refinegrains.lf(colf.tth, colf.eta)\n",
    "        cor_intensity *= lf\n",
    "    order = np.argsort( cor_intensity )[::-1] # sort the peaks by intensity\n",
    "    sortedpks = cor_intensity[order]\n",
    "    cums =  np.cumsum(sortedpks)\n",
    "    cums /= cums[-1]\n",
    "    enough = np.searchsorted(cums, frac)\n",
    "    # Aim is to select the strongest peaks for indexing.\n",
    "    cutoff = sortedpks[enough]\n",
    "    mask = cor_intensity > cutoff\n",
    "    if doplot is not None:\n",
    "        fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "        axs[0].plot(cums/cums[-1], ',')\n",
    "        axs[0].set(xlabel='npks',ylabel='fractional intensity')\n",
    "        axs[0].plot([mask.sum(),], [frac,], \"o\" )\n",
    "        axs[1].plot(cums/cums[-1], ',')\n",
    "        axs[1].set(xlabel='npks logscale',ylabel='fractional intensity', xscale='log', ylim=(doplot,1.), \n",
    "                 xlim=(np.searchsorted(cums, doplot), len(cums)))\n",
    "        axs[1].plot( [mask.sum(),], [frac,], \"o\" )\n",
    "        plt.show()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_4d) to select only the strongest ones for indexing\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until the orange dot sits nicely on the \"elbow\" of the blue line\n",
    "# this indicates the fractional intensity cutoff we will select\n",
    "# if the blue line does not look elbow-shaped in the logscale plot, try changing the \"doplot\" parameter (the y scale of the logscale plot) until it does\n",
    "\n",
    "ms = strongest_peaks(cf_4d, frac=0.99, doplot=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# strongest_peaks returns a mask for cf_4d, so now we filter the peaks by the mask to keep only the brightest ones\n",
    "\n",
    "cf_4d.filter(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can take a look at the intensities of the remaining peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cf_4d.tth, cf_4d.sum_intensity,',')\n",
    "ax.semilogy()\n",
    "\n",
    "ax.set_xlabel(\"Two-theta\")\n",
    "ax.set_ylabel(\"Intensity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can define a unit cell from our parameters\n",
    "\n",
    "Fe = ImageD11.unitcell.unitcell_from_parameters(cf_4d.parameters)\n",
    "Fe.makerings(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's plot our peaks again, with the rings from the unitcell included, to check our lattice parameters are good\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "skip=1\n",
    "ax.plot( cf_4d.ds[::skip], cf_4d.eta[::skip],',',alpha=0.5)\n",
    "ax.plot( Fe.ringds, [0,]*len(Fe.ringds), '|', ms=90 )\n",
    "ax.set_xlabel('1 / d ($\\AA$)')\n",
    "ax.set_ylabel('$\\\\eta$ (deg)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's copy our 4D peaks to a new object, so we can filter them for indexing\n",
    "\n",
    "cf_4d_to_index = cf_4d.copy()\n",
    "\n",
    "# remove peaks with two-theta > 25 (edge of detector)\n",
    "\n",
    "cf_4d_to_index.filter(cf_4d_to_index.tth < 25)\n",
    "\n",
    "# specify our ImageD11 indexer with these peaks\n",
    "\n",
    "indexer = ImageD11.indexing.indexer_from_colfile(cf_4d_to_index)\n",
    "\n",
    "print(f\"Indexing {cf_4d_to_index.nrows} peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: set a tolerance in d-space (for assigning peaks to powder rings)\n",
    "\n",
    "indexer.ds_tol = 0.01\n",
    "\n",
    "# change the log level so we can see what the ring assigments look like\n",
    "\n",
    "ImageD11.indexing.loglevel = 1\n",
    "\n",
    "# assign peaks to powder rings\n",
    "\n",
    "indexer.assigntorings()\n",
    "\n",
    "# change log level back again\n",
    "\n",
    "ImageD11.indexing.loglevel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's plot the assigned peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# indexer.ra is the ring assignments\n",
    "\n",
    "ax.scatter(cf_4d_to_index.ds, cf_4d_to_index.eta, c=indexer.ra, cmap='tab20', s=1)\n",
    "ax.set_xlabel(\"d-star\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the maximum expected peaks\n",
    "allpks = np.sum([len(indexer.unitcell.ringhkls[ds]) for ds in indexer.unitcell.ringds])\n",
    "allpks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we are indexing!\n",
    "# USER: specify the rings you want to use for indexing\n",
    "rings = 2, 4, 6, 1\n",
    "\n",
    "# USER: specify the HKL tolerances you want to use for indexing\n",
    "\n",
    "# hkl_tols_seq = [0.050, 0.025, 0.010]\n",
    "hkl_tols_seq = [0.04]\n",
    "\n",
    "# USER: specify the fraction of the total expected peaks\n",
    "\n",
    "# fracs = (0.75, 0.5)\n",
    "fracs = [0.75]\n",
    "\n",
    "ImageD11.cImageD11.cimaged11_omp_set_num_threads(1)\n",
    "ImageD11.indexing.loglevel=3\n",
    "\n",
    "# iterate over HKL tolerances\n",
    "for tol in hkl_tols_seq:\n",
    "    # iterate over minpks fractions\n",
    "    for frac in fracs:\n",
    "        for indexer.ring_1 in rings:\n",
    "            for indexer.ring_2 in rings:\n",
    "                indexer.minpks = allpks*frac\n",
    "                indexer.hkl_tol = tol\n",
    "                indexer.find()\n",
    "                indexer.scorethem()                \n",
    "        print(frac, tol, len(indexer.ubis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_index_results(ind, colfile, title):\n",
    "    # Generate a histogram of |drlv| for a ubi matrix\n",
    "    indexer.histogram_drlv_fit()\n",
    "    indexer.fight_over_peaks()\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 2, layout=\"constrained\", figsize=(9,12))\n",
    "    axs_flat = axs.ravel()\n",
    "    \n",
    "    # For each grain, plot the error in hkl vs the number of peaks with that error\n",
    "    \n",
    "    for grh in ind.histogram:\n",
    "        axs_flat[0].plot(ind.bins[1:-1], grh[:-1], \"-\")\n",
    "    \n",
    "    axs_flat[0].set(ylabel=\"number of peaks\",\n",
    "                    xlabel=\"error in hkl (e.g. hkl versus integer)\",\n",
    "                    title=title)\n",
    "    \n",
    "    # set a mask of all non-assigned g-vectors\n",
    "    \n",
    "    m = ind.ga == -1\n",
    "    \n",
    "    # plot the assigned g-vectors omega vs dty (sinograms)\n",
    "    \n",
    "    axs_flat[1].scatter(colfile.omega[~m],\n",
    "                        colfile.dty[~m],\n",
    "                        c=ind.ga[~m],\n",
    "                        s=2,\n",
    "                        cmap='tab20')\n",
    "    \n",
    "    axs_flat[1].set(title=f'Sinograms of {ind.ga.max()+1} grains',\n",
    "                    xlabel='Omega/deg',\n",
    "                    ylabel='dty/um')\n",
    "    \n",
    "    # Define weak peaks as all non-assigned peaks with intensity 1e-4 of max\n",
    "    cut = colfile.sum_intensity[m].max() * 1e-4\n",
    "    weak = colfile.sum_intensity[m] < cut\n",
    "    \n",
    "    # Plot unassigned peaks in omega vs dty\n",
    "    \n",
    "    axs_flat[2].scatter(colfile.omega[m][weak],  colfile.dty[m][weak],  s=2, label='weak')\n",
    "    axs_flat[2].scatter(colfile.omega[m][~weak], colfile.dty[m][~weak], s=2, label='not weak')\n",
    "    \n",
    "    axs_flat[2].set(title='Sinograms of unassigned peaks',\n",
    "                    xlabel='Omega/deg',\n",
    "                    ylabel='dty/um')\n",
    "    axs_flat[2].legend()\n",
    "    \n",
    "    # Plot d-star vs intensity for all assigned peaks\n",
    "    \n",
    "    axs_flat[3].scatter(colfile.ds[~m], colfile.sum_intensity[~m], s=2)\n",
    "    axs_flat[3].set(title='Intensity of all assigned peaks',\n",
    "                    xlabel='d-star',\n",
    "                    ylabel='Intensity',\n",
    "                    yscale='log')\n",
    "    \n",
    "    # Plot d-star vs intensity for all unassigned peaks\n",
    "    \n",
    "    axs_flat[4].scatter(colfile.ds[m][weak],  colfile.sum_intensity[m][weak],  s=2, label='weak')\n",
    "    axs_flat[4].scatter(colfile.ds[m][~weak], colfile.sum_intensity[m][~weak], s=2, label='not weak')\n",
    "    \n",
    "    axs_flat[4].set(title='Intensity of all unassigned peaks',\n",
    "                    xlabel='d-star',\n",
    "                    ylabel='Intensity',\n",
    "                    yscale='log')\n",
    "    axs_flat[4].legend()\n",
    "    \n",
    "    # Get the number of peaks per grain\n",
    "    \n",
    "    npks = [(ind.ga == i).sum() for i in range(len(ind.ubis))]\n",
    "    \n",
    "    # Plot histogram of number of peaks per grain\n",
    "    \n",
    "    axs_flat[5].hist(npks, bins=64)\n",
    "    axs_flat[5].set(title='Hist of peaks per grain',\n",
    "                    xlabel='Number of peaks',\n",
    "                    ylabel='Number of grains')\n",
    "    \n",
    "    for ax in axs_flat:\n",
    "        ax.set_box_aspect(0.7)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_index_results(indexer, cf_4d_to_index, 'First attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Define HKL tolerance to try to assign all peaks to existing grains\n",
    "\n",
    "hkl_tol = 0.04\n",
    "\n",
    "# Get an array of g-vectors from the columnfile\n",
    "gvectors = np.transpose((cf_4d.gx, cf_4d.gy, cf_4d.gz)).copy()\n",
    "n_gvectors = len(gvectors)\n",
    "\n",
    "# Make storage arrays for errors (drlv2) and labels\n",
    "# both arrays are persistent throughout assigments\n",
    "# so they get steadily improved over time\n",
    "drlv2 = np.full(n_gvectors, 2, dtype=float)\n",
    "labels = np.full(n_gvectors, -1, 'i')\n",
    "\n",
    "# Create array of grain objects, one per UBI matrix from indexer.ubis\n",
    "grains = [ImageD11.grain.grain(ubi.copy()) for ubi in indexer.ubis]\n",
    "\n",
    "# print what fraction of the g-vectors are unassigned:\n",
    "print(f\"Trying to assign {cf_4d.nrows} peaks\")\n",
    "print(f\"Currently {(indexer.ga != -1).sum()/cf_4d.nrows} of peaks are assigned\")\n",
    "\n",
    "# Iterate over each UBI matrix\n",
    "for i, grain in enumerate(grains):\n",
    "    # Assign g-vectors to this grain if drlv2 < htl_tol**2\n",
    "    # Then refine the grain using all the assigned g-vectors\n",
    "    ImageD11.cImageD11.score_and_refine(grain.ubi, gvectors, hkl_tol)\n",
    "    ImageD11.cImageD11.score_and_refine(grain.ubi, gvectors, hkl_tol)\n",
    "    # assign all g-vectors to new refined grain\n",
    "    # will re-assign g-vectors if this grain gives a lower error than currently assigned\n",
    "    # updates drlv2 with new errors for new assignments\n",
    "    # updates labels with new assignments\n",
    "    ImageD11.cImageD11.score_and_assign(grain.ubi, gvectors, hkl_tol, drlv2, labels, i)\n",
    "    # pretend all g-vectors are unassigned\n",
    "    label_all_unassigned = np.full(n_gvectors, -1, 'i')\n",
    "    # pretend all grains have max error\n",
    "    drlv2_all_max = np.full(n_gvectors, 2, dtype=float)\n",
    "    # score and assign again\n",
    "    # updates drlv2_all_max with new errors for new assignments\n",
    "    # updates label_all_unassigned with new assignments\n",
    "    # now work out which g-vectors were assigned to this grain\n",
    "    # I think allpks is \"greedy\"\n",
    "    # In that it greedily assigns peaks to this grain assuming all other peaks are unassigned with max error\n",
    "    ImageD11.cImageD11.score_and_assign(grain.ubi, gvectors, hkl_tol, drlv2_all_max, label_all_unassigned, i)\n",
    "\n",
    "    grain.allpks = label_all_unassigned == i\n",
    "    # work out the sum of the intensities of all assigned g-vectors\n",
    "    grain.isum = cf_4d.sum_intensity[grain.allpks].sum()\n",
    "\n",
    "# # Iterate over each grain again after all assigned\n",
    "for i, grain in enumerate(grains):\n",
    "    # Get the assigned peaks for this grain\n",
    "    grain.pks = labels == i\n",
    "    # Get the total number of assigned peaks for this grain\n",
    "    grain.npks = grain.pks.sum()\n",
    "    \n",
    "    # Calculate the real hkls for each gvector of this grain\n",
    "    hklr = np.dot(grain.ubi, gvectors[grain.pks].T)\n",
    "    # Round them to integers\n",
    "    hkli = np.round(hklr).astype(int)\n",
    "    \n",
    "    # Work out the number of unique peaks per grain\n",
    "    # By removing duplicates\n",
    "    uniqpks = np.unique(np.vstack((hkli, np.sign(cf_4d.eta[grain.pks]).astype(int))),axis=1)\n",
    "    grain.nuniq = uniqpks.shape[1]\n",
    "\n",
    "print(f\"Now {(labels!=-1).sum()/len(labels)} of peaks are assigned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add labels as a new column in the columnfile\n",
    "\n",
    "cf_4d.addcolumn(labels, 'grain_id')\n",
    "\n",
    "# Delete the columnfile output file if it exists\n",
    "if os.path.exists(cf_path):\n",
    "    os.remove(cf_path)\n",
    "\n",
    "# Write columnfile as an HDF file\n",
    "ImageD11.columnfile.colfile_to_hdf(cf_4d, cf_path)\n",
    "\n",
    "# add UBIs as a new dataset\n",
    "# also add greedy peaks\n",
    "with h5py.File(cf_path,'a') as hout:\n",
    "    hout.create_dataset('ubis', data=np.array([grain.ubi for grain in grains]))\n",
    "    hout.create_dataset('ubis_allpks', data=np.array([grain.allpks for grain in grains]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
