{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc4bc96-cbc7-436a-a174-c99388869cbb",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 28/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b89030-fdb2-47d2-bc26-3e5cfb0d6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b91e0-7a83-462b-85cb-27f65721ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import timeit\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib ipympl\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xfab.symmetry import Umis\n",
    "\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.peakselect import select_ring_peaks_by_intensity\n",
    "from ImageD11.sinograms import properties, roi_iradon\n",
    "from ImageD11.sinograms import geometry\n",
    "from ImageD11.sinograms.sinogram import GrainSinogram, build_slice_arrays, write_slice_recon, read_slice_recon, write_h5, read_h5, write_pbp_strain\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import cImageD11\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff052b-cca8-4310-8b29-4c82e0e513c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "\n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b9af4-89a7-4dff-b258-cc2f77db5ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722e04a-a23f-4af3-8530-a90874e27e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick a phase\n",
    "phase_str = 'Si'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2b143-ed90-4817-92ac-bd78dea2c73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 2D peaks\n",
    "\n",
    "cf_2d = ds.get_cf_2d()\n",
    "ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "print(f\"Read {cf_2d.nrows} 4D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf5dc8-a25d-4b09-b1d8-e55b1c6d07b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import grainsinos\n",
    "\n",
    "grainsinos = read_h5(ds.grainsfile, ds, phase_str)\n",
    "grains = [gs.grain for gs in grainsinos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ff57a-0a7f-44cd-b437-eb4cc4e2ea25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import slice reconstructions\n",
    "\n",
    "tensor_map = TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8feef60-367b-478a-9ce4-8a94e3cedd60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter 2D peaks by intensity\n",
    "\n",
    "cf_2d_strong_frac = 0.999\n",
    "\n",
    "cf_2d_strong = select_ring_peaks_by_intensity(cf_2d, frac=cf_2d_strong_frac, dsmax=cf_2d.ds.max(), doplot=0.5)\n",
    "print(cf_2d.nrows)\n",
    "print(cf_2d_strong.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fe817-5794-459b-9974-9d70624af3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y0 = grainsinos[0].recon_y0\n",
    "recon_shape = grainsinos[0].recons[\"iradon\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cb2c4-50d1-4264-aef4-af903e4ce941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtyi = geometry.dty_to_dtyi(cf_2d_strong.dty, ystep=ds.ystep)\n",
    "\n",
    "cf_2d_strong.addcolumn(dtyi, \"dtyi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30167341-407e-4f98-9104-7d5db4ce0b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# what peaks could have come from this grain?\n",
    "# first, assign all peaks to grains \n",
    "\n",
    "peak_assign_tol = 0.025\n",
    "\n",
    "utils.assign_peaks_to_grains(grains, cf_2d_strong, tol=peak_assign_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee32ebb-12df-419e-856f-4112ba3b8fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_pixel_ubis = {}\n",
    "grain_lut = {}\n",
    "\n",
    "clean_pars = cf_2d_strong.parameters.get_parameters()\n",
    "\n",
    "for ginc, g in enumerate(tqdm(grains[:])):\n",
    "    grain_lut[ginc] = g\n",
    "    \n",
    "    # work out what 2D peaks this grain claims\n",
    "    g.mask_2d_strong = cf_2d_strong.grain_id == ginc\n",
    "\n",
    "    # get the 2D peaks for this grain only\n",
    "    # for now this will become the columnfile for the grain\n",
    "    g.cf = cf_2d_strong.copyrows(g.mask_2d_strong)\n",
    "    \n",
    "    # work out what pixels in the sample this grain claims\n",
    "    g.pixel_support_mask = tensor_map.labels == ginc\n",
    "    g.pixel_support_coords = np.argwhere(g.pixel_support_mask == True)\n",
    "    \n",
    "    if len(g.pixel_support_coords) == 0:\n",
    "        continue\n",
    "    \n",
    "    # right now, g.cf is just from the peak assignment\n",
    "    # could contain peaks that come from the wrong place in the sample\n",
    "    # solution: combine these 2 masks together\n",
    "    # isolates 2D peaks that index this grain and come from the grain spatially\n",
    "    \n",
    "    # this will mask g.cf based on pixel position\n",
    "    new_mask_2d_strong = np.zeros(g.cf.nrows).astype(bool)\n",
    "    \n",
    "    # iterate through the pixel positions\n",
    "    for mi, mj, mk in g.pixel_support_coords:\n",
    "        # get a peak mask associated with this pixel position in the sample\n",
    "        ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "        mask = geometry.dtyimask_from_recon(ri, rj, g.cf.omega, g.cf.dtyi, recon_shape=recon_shape, ystep=ds.ystep, y0=y0)\n",
    "        \n",
    "        # add it to the mask (| is OR)\n",
    "        new_mask_2d_strong |= mask\n",
    "    \n",
    "    g.cf = g.cf.copyrows(new_mask_2d_strong)\n",
    "    \n",
    "    gvecs_per_point = {}\n",
    "    all_tth_old = []\n",
    "    all_tth_new = []\n",
    "    all_omega = []\n",
    "    for mi, mj, mk in g.pixel_support_coords:\n",
    "        ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "        # get translation in the sample frame\n",
    "        sx, sy = geometry.recon_to_sample(ri, rj, recon_shape=recon_shape, ystep=ds.ystep)\n",
    "\n",
    "        # get a peak mask associated with this pixel position in the sample\n",
    "        pixel_mask = geometry.dtyimask_from_recon(ri, rj, g.cf.omega, g.cf.dtyi, recon_shape=recon_shape, ystep=ds.ystep, y0=y0)\n",
    "        \n",
    "        # get the x translation of the peak in the lab reference frame\n",
    "        \n",
    "        lx, _ = geometry.sample_to_lab(sx, sy, y0, g.cf.dtyi[pixel_mask], g.cf.omega[pixel_mask])\n",
    "        \n",
    "        new_pars = clean_pars.copy()\n",
    "        new_pars['distance'] = new_pars['distance'] - lx\n",
    "        \n",
    "        tth, eta = ImageD11.transform.compute_tth_eta(\n",
    "                        (g.cf.sc[pixel_mask], g.cf.fc[pixel_mask]),\n",
    "                        **new_pars)\n",
    "\n",
    "        gve = ImageD11.transform.compute_g_vectors(tth,\n",
    "                            eta,\n",
    "                            g.cf.omega[pixel_mask],\n",
    "                            new_pars['wavelength'],\n",
    "                            wedge=new_pars['wedge'],\n",
    "                            chi=new_pars['chi'])\n",
    "        \n",
    "        # save gvecs\n",
    "        gvecs_per_point[ri, rj] = gve.T\n",
    "    \n",
    "    # concatenate all gvecs together to compute refined ubi\n",
    "    all_gvecs = np.vstack([gve for gve in gvecs_per_point.values()])\n",
    "\n",
    "    ubifit = g.ubi.copy()\n",
    "    _ = cImageD11.score_and_refine(ubifit, all_gvecs, peak_assign_tol)\n",
    "    g.set_ubi(ubifit)\n",
    "\n",
    "    # now iterate through each pixel position\n",
    "    for mi, mj, mk in g.pixel_support_coords:\n",
    "        ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "        # we already have the recomputed g-vectors\n",
    "        gvecs_here = gvecs_per_point[ri, rj]\n",
    "        ubifit = g.ubi.copy()\n",
    "        _ = cImageD11.score_and_refine(ubifit, gvecs_here, peak_assign_tol)\n",
    "        per_pixel_ubis[ri, rj] = (ginc, ubifit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af22d1-e035-4cb3-92d1-cc7f0aedc983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validate masking\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cf_2d_strong.omega[cf_2d_strong.grain_id == ginc], cf_2d_strong.dty[cf_2d_strong.grain_id == ginc], label='cf_2d_strong assignments')\n",
    "ax.scatter(g.cf.omega, g.cf.dty, label='grain cf - spatially filtered')\n",
    "ax.scatter(g.cf.omega[pixel_mask], g.cf.dty[pixel_mask], label='pixel mask')\n",
    "ax.invert_yaxis()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55a7b0-47da-4be2-9618-7b8fd0055619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# determine a UBI per pixel\n",
    "\n",
    "ubi_map = np.empty((recon_shape + (3,3)))\n",
    "ubi_map.fill(np.nan)\n",
    "for pxi in tqdm(range(recon_shape[0])):\n",
    "    for pxj in range(recon_shape[1]):\n",
    "        try:\n",
    "            graininc, this_ubi = per_pixel_ubis[pxi, pxj]\n",
    "            ubi_map[pxi, pxj, :, :] = this_ubi\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f4e6a-c35b-478a-8fa7-57fc6734ec8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ubi_map_tmap = tensor_map.recon_order_to_map_order(ubi_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda392a-86f4-4256-9ce9-d509e90af57e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map.add_map('UBI_refined', ubi_map_tmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe823aa-516a-495a-9610-72f28c21f34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(tensor_map.UBI[0, :, :, 0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274c5fd-22ac-4e08-b62a-a0cad950a132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(tensor_map.UBI_refined[0, :, :, 0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317ff69-d71d-4822-afb3-8d4334706608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map.UBI = tensor_map.UBI_refined\n",
    "tensor_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d5758-d50b-4709-87bc-2477afb0a0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(tensor_map.unitcell[0, :, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18434f17-c65b-4221-aac9-58a82bcdc463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rel_vol_strain_map = np.full(tensor_map.phase_ids.shape, np.nan, float)\n",
    "abs_vol_strain_map = np.full(tensor_map.phase_ids.shape, np.nan, float)\n",
    "\n",
    "NZ, NY, NX = tensor_map.shape\n",
    "\n",
    "for mi in range(NZ):\n",
    "    for mj in range(NY):\n",
    "        for mk in range(NX):\n",
    "            # get the unitcell at this position\n",
    "            unitcell_px = tensor_map.unitcell[mi, mj, mk]\n",
    "            # get the grain label at this position\n",
    "            label_px = tensor_map.labels[mi, mj, mk]\n",
    "            # get the grain at this position\n",
    "            grain_px = grains[label_px]\n",
    "            unitcell_px_meanlength = np.mean(unitcell_px[:3])\n",
    "            grain_px_meanlength = np.mean(grain_px.unitcell[:3])\n",
    "            ref_ucell_meanlength = np.mean(ds.phases.unitcells[phase_str].lattice_parameters[:3])\n",
    "            rel_vol_strain = (unitcell_px_meanlength - grain_px_meanlength) / grain_px_meanlength\n",
    "            abs_vol_strain = (unitcell_px_meanlength - ref_ucell_meanlength) / ref_ucell_meanlength\n",
    "            rel_vol_strain_map[mi, mj, mk] = rel_vol_strain\n",
    "            abs_vol_strain_map[mi, mj, mk] = abs_vol_strain\n",
    "\n",
    "tensor_map.add_map('rel_vol_strain', rel_vol_strain_map)\n",
    "tensor_map.add_map('abs_vol_strain', abs_vol_strain_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d325ce1-80a3-4015-9ab6-23ba3f9cc4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(tensor_map.rel_vol_strain[0, :, :]*1e3, cmap='RdBu')\n",
    "plt.colorbar(im)\n",
    "plt.title('Relative volumetric strain (1e-3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e3c56-24c6-4b4a-8bd8-1a8f99df4523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(tensor_map.abs_vol_strain[0, :, :]*1e3, cmap='RdBu')\n",
    "plt.colorbar(im)\n",
    "plt.title('Absolute volumetric strain (1e-3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6de934-6aca-4179-a17d-3921cf1098a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the TensorMap to disk too\n",
    "\n",
    "tensor_map.to_h5(ds.grainsfile, h5group='TensorMap_' + phase_str + '_refined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe8728-92a1-4acf-be4a-bac8b33beb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c559091-97bd-4b2d-9dc6-d99eb1b6e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51473acc-dfa2-4a1e-8380-dd5c5c953e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if not os.path.exists(ds.grainsfile):\n",
    "            print(f\"Missing grains file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        # check grains file for existance of output, skip if it's there\n",
    "        with h5py.File(ds.grainsfile, \"r\") as hin:\n",
    "            if 'TensorMap_' + phase_str + '_refined' in hin.keys():\n",
    "                print(f\"Already reconstructed {dataset} in {sample}, skipping\")\n",
    "                continue\n",
    "        \n",
    "        ds.phases = ds.get_phases_from_disk()\n",
    "        \n",
    "        cf_2d = ds.get_cf_2d()\n",
    "        ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "        grainsinos = read_h5(ds.grainsfile, ds, phase_str)\n",
    "        grains = [gs.grain for gs in grainsinos]\n",
    "        \n",
    "        tensor_map = TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)\n",
    "        \n",
    "        cf_2d_strong = select_ring_peaks_by_intensity(cf_2d, frac=cf_2d_strong_frac, dsmax=cf_2d.ds.max())\n",
    "        y0 = grainsinos[0].recon_y0\n",
    "        recon_shape = grainsinos[0].recons[\"astra\"].shape\n",
    "\n",
    "        dtyi = geometry.dty_to_dtyi(cf_2d_strong.dty, ystep=ds.ystep)\n",
    "        cf_2d_strong.addcolumn(dtyi, \"dtyi\")\n",
    "        \n",
    "        utils.assign_peaks_to_grains(grains, cf_2d_strong, tol=peak_assign_tol)\n",
    "\n",
    "        per_pixel_ubis = {}\n",
    "        grain_lut = {}\n",
    "\n",
    "        clean_pars = cf_2d_strong.parameters.get_parameters()\n",
    "\n",
    "        for ginc, g in enumerate(tqdm(grains[:])):\n",
    "            grain_lut[ginc] = g\n",
    "\n",
    "            # work out what 2D peaks this grain claims\n",
    "            g.mask_2d_strong = cf_2d_strong.grain_id == ginc\n",
    "\n",
    "            # get the 2D peaks for this grain only\n",
    "            # for now this will become the columnfile for the grain\n",
    "            g.cf = cf_2d_strong.copyrows(g.mask_2d_strong)\n",
    "\n",
    "            # work out what pixels in the sample this grain claims\n",
    "            g.pixel_support_mask = tensor_map.labels == ginc\n",
    "            g.pixel_support_coords = np.argwhere(g.pixel_support_mask == True)\n",
    "\n",
    "            if len(g.pixel_support_coords) == 0:\n",
    "                continue\n",
    "\n",
    "            # right now, g.cf is just from the peak assignment\n",
    "            # could contain peaks that come from the wrong place in the sample\n",
    "            # solution: combine these 2 masks together\n",
    "            # isolates 2D peaks that index this grain and come from the grain spatially\n",
    "\n",
    "            # this will mask g.cf based on pixel position\n",
    "            new_mask_2d_strong = np.zeros(g.cf.nrows).astype(bool)\n",
    "\n",
    "            # iterate through the pixel positions\n",
    "            for mi, mj, mk in g.pixel_support_coords:\n",
    "                # get a peak mask associated with this pixel position in the sample\n",
    "                ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "                mask = geometry.dtyimask_from_recon(ri, rj, g.cf.omega, g.cf.dtyi, recon_shape=recon_shape, ystep=ds.ystep, y0=y0)\n",
    "\n",
    "                # add it to the mask (| is OR)\n",
    "                new_mask_2d_strong |= mask\n",
    "\n",
    "            g.cf = g.cf.copyrows(new_mask_2d_strong)\n",
    "\n",
    "            gvecs_per_point = {}\n",
    "            all_tth_old = []\n",
    "            all_tth_new = []\n",
    "            all_omega = []\n",
    "            for mi, mj, mk in g.pixel_support_coords:\n",
    "                ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "                # get translation in the sample frame\n",
    "                sx, sy = geometry.recon_to_sample(ri, rj, recon_shape=recon_shape, ystep=ds.ystep)\n",
    "\n",
    "                # get a peak mask associated with this pixel position in the sample\n",
    "                pixel_mask = geometry.dtyimask_from_recon(ri, rj, g.cf.omega, g.cf.dtyi, recon_shape=recon_shape, ystep=ds.ystep, y0=y0)\n",
    "\n",
    "                # get the x translation of the peak in the lab reference frame\n",
    "\n",
    "                lx, _ = geometry.sample_to_lab(sx, sy, y0, g.cf.dtyi[pixel_mask], g.cf.omega[pixel_mask])\n",
    "\n",
    "                new_pars = clean_pars.copy()\n",
    "                new_pars['distance'] = new_pars['distance'] - lx\n",
    "\n",
    "                tth, eta = ImageD11.transform.compute_tth_eta(\n",
    "                                (g.cf.sc[pixel_mask], g.cf.fc[pixel_mask]),\n",
    "                                **new_pars)\n",
    "\n",
    "                gve = ImageD11.transform.compute_g_vectors(tth,\n",
    "                                    eta,\n",
    "                                    g.cf.omega[pixel_mask],\n",
    "                                    new_pars['wavelength'],\n",
    "                                    wedge=new_pars['wedge'],\n",
    "                                    chi=new_pars['chi'])\n",
    "\n",
    "                # save gvecs\n",
    "                gvecs_per_point[ri, rj] = gve.T\n",
    "\n",
    "            # concatenate all gvecs together to compute refined ubi\n",
    "            all_gvecs = np.vstack([gve for gve in gvecs_per_point.values()])\n",
    "\n",
    "            ubifit = g.ubi.copy()\n",
    "            _ = cImageD11.score_and_refine(ubifit, all_gvecs, peak_assign_tol)\n",
    "            g.set_ubi(ubifit)\n",
    "\n",
    "            # now iterate through each pixel position\n",
    "            for mi, mj, mk in g.pixel_support_coords:\n",
    "                ri, rj = tensor_map.map_index_to_recon(mj, mk, yshape=tensor_map.shape[1])\n",
    "                # we already have the recomputed g-vectors\n",
    "                gvecs_here = gvecs_per_point[ri, rj]\n",
    "                ubifit = g.ubi.copy()\n",
    "                _ = cImageD11.score_and_refine(ubifit, gvecs_here, peak_assign_tol)\n",
    "                per_pixel_ubis[ri, rj] = (ginc, ubifit)\n",
    "\n",
    "        ubi_map = np.empty((recon_shape + (3,3)))\n",
    "        ubi_map.fill(np.nan)\n",
    "        for pxi in tqdm(range(recon_shape[0])):\n",
    "            for pxj in range(recon_shape[1]):\n",
    "                try:\n",
    "                    graininc, this_ubi = per_pixel_ubis[pxi, pxj]\n",
    "                    ubi_map[pxi, pxj, :, :] = this_ubi\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        \n",
    "        ubi_map_tmap = tensor_map.recon_order_to_map_order(ubi_map)\n",
    "        tensor_map.UBI = tensor_map.UBI_refined\n",
    "        eul = tensor_map.euler\n",
    "        \n",
    "        rel_vol_strain_map = np.full(tensor_map.phase_ids.shape, np.nan, float)\n",
    "        abs_vol_strain_map = np.full(tensor_map.phase_ids.shape, np.nan, float)\n",
    "\n",
    "        NZ, NY, NX = tensor_map.shape\n",
    "\n",
    "        for mi in range(NZ):\n",
    "            for mj in range(NY):\n",
    "                for mk in range(NX):\n",
    "                    # get the unitcell at this position\n",
    "                    unitcell_px = tensor_map.unitcell[mi, mj, mk]\n",
    "                    # get the grain label at this position\n",
    "                    label_px = tensor_map.labels[mi, mj, mk]\n",
    "                    # get the grain at this position\n",
    "                    grain_px = grains[label_px]\n",
    "                    unitcell_px_meanlength = np.mean(unitcell_px[:3])\n",
    "                    grain_px_meanlength = np.mean(grain_px.unitcell[:3])\n",
    "                    ref_ucell_meanlength = np.mean(ds.phases.unitcells[phase_str].lattice_parameters[:3])\n",
    "                    rel_vol_strain = (unitcell_px_meanlength - grain_px_meanlength) / grain_px_meanlength\n",
    "                    abs_vol_strain = (unitcell_px_meanlength - ref_ucell_meanlength) / ref_ucell_meanlength\n",
    "                    rel_vol_strain_map[mi, mj, mk] = rel_vol_strain\n",
    "                    abs_vol_strain_map[mi, mj, mk] = abs_vol_strain\n",
    "\n",
    "        tensor_map.add_map('rel_vol_strain', rel_vol_strain_map)\n",
    "        tensor_map.add_map('abs_vol_strain', abs_vol_strain_map)\n",
    "        \n",
    "        tensor_map.to_h5(ds.grainsfile, h5group='TensorMap_' + phase_str + '_refined')\n",
    "\n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73580e-108c-4d95-8437-a6ce7f890326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
