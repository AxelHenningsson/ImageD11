{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc4bc96-cbc7-436a-a174-c99388869cbb",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 28/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636849a2-54fd-44ce-aca3-cb8e7e945e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b89030-fdb2-47d2-bc26-3e5cfb0d6509",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged with 'parameters'\n",
    "# to view the tag, select the cell, then find the settings gear icon (right or left sidebar) and look for Cell Tags\n",
    "\n",
    "# python environment stuff\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )\n",
    "\n",
    "# dataset file to import\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "phase_strs = ['Fe', 'Au']\n",
    "\n",
    "# whether or not we are combining refined tensormaps (changes where we look for them)\n",
    "combine_refined = True\n",
    "\n",
    "dset_prefix = \"top_\"  # some common string in the names of the datasets if processing multiple scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b91e0-7a83-462b-85cb-27f65721ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import timeit\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ImageD11.sinograms.sinogram import GrainSinogram, build_slice_arrays, write_slice_recon, read_slice_recon, write_h5, read_h5\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms import properties, roi_iradon\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.blobcorrector import eiger_spatial\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import cImageD11\n",
    "from xfab.parameters import read_par_file\n",
    "\n",
    "from ImageD11.nbGui import nb_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c559a5-0202-4f54-be32-20830f5fd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bb37b-8fd2-40a0-b3e8-e9ce2451fc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bababb-461c-41a1-898d-378418fdc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what phases are we merging?\n",
    "\n",
    "print(*[ds.phases.unitcells[phase_str].lattice_parameters for phase_str in phase_strs], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e458287-439b-4dff-ac5b-2855a1f94f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to import your TensorMaps from\n",
    "# if you refined them, you'll need to change the below paths to point to the separate refined tensormap h5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95ef6a-6267-4403-a2e4-0bcbb59350b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if combine_refined:\n",
    "    tensor_maps = [TensorMap.from_h5(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_refined_tmap_{phase_str}.h5')) for phase_str in phase_strs]\n",
    "else:\n",
    "    tensor_maps = [TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str) for phase_str in phase_strs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5e081-feda-4dee-a260-36f4f286ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for tmap in tensor_maps:\n",
    "        tmap.plot('labels')\n",
    "except KeyError:\n",
    "    # no labels field\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c9219-2c22-4db6-9c64-150fc286cb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map_combined = TensorMap.from_combine_phases(tensor_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5baf01-2f49-4c44-bf6c-7b39a165b29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map_combined.plot('phase_ids')\n",
    "try:\n",
    "    tensor_map_combined.plot('labels')\n",
    "except KeyError:\n",
    "    # no labels field\n",
    "    pass\n",
    "tensor_map_combined.plot('ipf_z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bccb3c-9338-4202-a5c1-6292183836dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if combine_refined:\n",
    "    tensor_map_combined.to_h5(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_refined_tmap_combined.h5'))\n",
    "    tensor_map_combined.to_paraview(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_refined_tmap_combined.h5'))\n",
    "else:\n",
    "    tensor_map_combined.to_h5(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_tmap_combined.h5'))\n",
    "    tensor_map_combined.to_paraview(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_tmap_combined.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bf9ac-16ca-4492-9bd4-e5eb1979fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "# you can optionally skip samples\n",
    "# skips_dict = {\n",
    "#     \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "# }\n",
    "# otherwise by default skip nothing:\n",
    "skips_dict = {\n",
    "    ds.sample: []\n",
    "}\n",
    "\n",
    "sample_list = [ds.sample, ]\n",
    "\n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if combine_refined:\n",
    "            combined_tmap_path = os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_refined_tmap_combined.h5')\n",
    "        else:\n",
    "            combined_tmap_path = os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_tmap_combined.h5')\n",
    "        \n",
    "        if os.path.exists(combined_tmap_path):\n",
    "            print(f\"Already have combined TensorMap output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        if combine_refined:\n",
    "            tensor_maps = [TensorMap.from_h5(os.path.join(ds.analysispath, f'{ds.sample}_{ds.dset}_refined_tmap_{phase_str}.h5')) for phase_str in phase_strs]\n",
    "        else:\n",
    "            tensor_maps = [TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str) for phase_str in phase_strs]\n",
    "        tensor_map_combined = TensorMap.from_combine_phases(tensor_maps)\n",
    "        \n",
    "        tensor_map_combined.to_h5(combined_tmap_path)\n",
    "        tensor_map_combined.to_paraview(combined_tmap_path)\n",
    "        \n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
